{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンソールで設定したSparkとNoteBookを接続します(動かす前に毎度実行する必要があります)\n",
    "import findspark\n",
    "findspark.init(\"/home/pyspark/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pysparkに必要なライブラリを読み込む\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark sessionの作成\n",
    "# spark.ui.enabled trueとするとSparkのGUI画面を確認することができます\n",
    "# spark.eventLog.enabled true　とすると　GUIで実行ログを確認することができます\n",
    "# GUIなどの確認は最後のセクションで説明を行います。\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"chapter1\") \\\n",
    "    .config(\"hive.exec.dynamic.partition\", \"true\") \\\n",
    "    .config(\"hive.exec.dynamic.partition.mode\", \"nonstrict\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"JST\") \\\n",
    "    .config(\"spark.ui.enabled\",\"true\") \\\n",
    "    .config(\"spark.eventLog.enabled\",\"true\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# spark.xxxxxと記載することで処理を分散させることが可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今回利用するデータの確認\n",
    "\n",
    "今回は、datafileフォルダ配下の\n",
    "\n",
    "- jinko.csv(各年代の都道府県ごとの人口)\n",
    "- kenmei_master.csv(都道府県コードをまとめている)\n",
    "\n",
    "を利用していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　データの読み込みを行う\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "struct = StructType([\n",
    "    StructField(\"code\", StringType(), False),\n",
    "    StructField(\"gengo\", StringType(), False),\n",
    "    StructField(\"wareki\", StringType(), False),\n",
    "    StructField(\"seireki\", StringType(), False),\n",
    "    StructField(\"chu\", StringType(), False),\n",
    "    StructField(\"sokei\", StringType(), False),\n",
    "    StructField(\"jinko_male\", StringType(), False),\n",
    "    StructField(\"jinko_female\", StringType(), False)\n",
    "])\n",
    "df=spark.read.option(\"multiLine\", \"true\").option(\"encoding\", \"UTF-8\") \\\n",
    "    .csv(\"./datafile/jinko.csv\", header=False, sep=',', inferSchema=False,schema=struct)\n",
    "\n",
    "struct2 = StructType([\n",
    "    StructField(\"code\", StringType(), False),\n",
    "    StructField(\"kenmei\", StringType(), False)\n",
    "])\n",
    "df2=spark.read.option(\"multiLine\", \"true\").option(\"encoding\", \"UTF-8\") \\\n",
    "    .csv(\"./datafile/kenmei_master.csv\", header=False, sep=',', inferSchema=False,schema=struct2)\n",
    "\n",
    "\n",
    "struct3 = StructType([\n",
    "    StructField(\"codes\", StringType(), False),\n",
    "    StructField(\"kenmei\", StringType(), False)\n",
    "])\n",
    "df3=spark.read.option(\"multiLine\", \"true\").option(\"encoding\", \"UTF-8\") \\\n",
    "    .csv(\"./datafile/kenmei_master.csv\", header=False, sep=',', inferSchema=False,schema=struct3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# タグクオリティの算出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# タグクオリティ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今までのテスト結果をデータフレームに保存してみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の結合をおこなってdf_resultデータフレームに保存します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mysqlへのデータ書き込み\n",
    "# mysqlのテーブルは勝手に作ってくれます。\n",
    "\n",
    "df_result.write.format('jdbc').options(\n",
    "      url='jdbc:mysql://db_mysql/metadata?enabledTLSProtocols=TLSv1.2',\n",
    "      driver='com.mysql.jdbc.Driver',\n",
    "      dbtable='metadatas',\n",
    "      user='root',\n",
    "      password='root').mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mysqlでの確認をしてみましょう\n",
    "\n",
    "```\n",
    "mysql -h db_mysql -u root -proot  metadata\n",
    "select * from metadatas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後はSparkをクローズする\n",
    "spark.stop()\n",
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cadefa720d1a2267f4d12d08d812560a64cfe891877bc388bf0e8af3e4846067"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
